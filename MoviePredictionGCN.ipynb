{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MoviePredictionGCN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parkererickson/GCNMoviePrediction/blob/master/MoviePredictionGCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14Qxtu0mPcat",
        "colab_type": "text"
      },
      "source": [
        "<p><img alt=\"TigerGraph logo\" height=\"45px\" src=\"https://blobscdn.gitbook.com/v0/b/gitbook-28427.appspot.com/o/spaces%2F-LHvjxIN4__6bA0T-QmU%2Favatar.png?generation=1532158270801864&amp;alt=media\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "# Graph Convolutional Neural Networks for Movie Recommendation\n",
        "------\n",
        "## Introduction\n",
        "This notebook walks through a basic example of using a graph convolutional neural network (GCN) for recommendation. The data is collected from a TigerGraph database using a Python package [pyTigerGraph](https://github.com/parkererickson/pyTigerGraph). Data collected is then pushed through a GCN to output predictions about a person's viewing preferences. This example does makes a couple oversimplifications that will be pointed out, mainly in the assumptions made surrounding a person's preferences. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlYp_HBZMMZg",
        "colab_type": "text"
      },
      "source": [
        "## Install Queries on TigerGraph Server\n",
        "You need to create and install two queries on the TigerGraph server; one named userRatings and another called movieLinks.\n",
        "\n",
        "```\n",
        "CREATE QUERY userRatings(VERTEX<USER> user) FOR GRAPH Recommender { \n",
        "  /* movieID | userID | userRating | term | termRating */\n",
        "  SumAccum<float> @rating;\n",
        "\t\n",
        "\tsrc = {user};\n",
        "  \n",
        "\tS1 = SELECT tgt FROM src:s -(rate:e)-> MOVIE:tgt\n",
        "       ACCUM tgt.@rating += e.rating;\n",
        "\n",
        "  PRINT S1[S1.movie_id as movieID, S1.name as movieTitle, S1.@rating as userRating];\n",
        "}\n",
        "```\n",
        "\n",
        "```\n",
        "CREATE QUERY movieLinks() FOR GRAPH Recommender SYNTAX v2{ \n",
        "\tTYPEDEF TUPLE <STRING src, STRING dest> TUPLE_RECORD;\n",
        "\tListAccum<TUPLE_RECORD> @@tupleRecords;\n",
        "\tmovies = {MOVIE.*};  \n",
        "\tresult = SELECT tgt FROM movies:s-(:e1)-TERM:mid-(:e2)-MOVIE:tgt WHERE s != tgt \n",
        "\t         ACCUM @@tupleRecords += TUPLE_RECORD (s.name, tgt.name);\n",
        "\tPRINT @@tupleRecords;\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvPS7TtM4Q_g",
        "colab_type": "text"
      },
      "source": [
        "## Installing Packages\n",
        "The core packages that need to be installed are PyTorch, dgl, and pyTigerGraph. PyTorch and dgl are used for creating and training the GCN, while pyTigerGraph is used for connecting to the TigerGraph database. We also import networkx for converting the list of edges from TigerGraph into a graph dgl can work with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMXcHVwCxWtR",
        "colab_type": "code",
        "outputId": "c9e0e952-2139-4b47-f439-ddf8e86ace33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        }
      },
      "source": [
        "!pip install pyTigerGraph\n",
        "!pip install torch torchvision\n",
        "!pip install dgl\n",
        "!pip install networkx"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyTigerGraph\n",
            "  Downloading https://files.pythonhosted.org/packages/59/d1/cc51f54b48d65e3fd6430ec4162b5a84be78cf9532fa8efdbd63773ed340/pyTigerGraph-0.0.4.6.tar.gz\n",
            "Collecting validators\n",
            "  Downloading https://files.pythonhosted.org/packages/72/8a/f99287daae8cfef938e6eec785f6e259bf6bad93269d5398bb546d5b1563/validators-0.14.1.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pyTigerGraph) (2.21.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from validators->pyTigerGraph) (1.12.0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from validators->pyTigerGraph) (4.4.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pyTigerGraph) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pyTigerGraph) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pyTigerGraph) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pyTigerGraph) (3.0.4)\n",
            "Building wheels for collected packages: pyTigerGraph, validators\n",
            "  Building wheel for pyTigerGraph (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyTigerGraph: filename=pyTigerGraph-0.0.4.6-cp36-none-any.whl size=3410 sha256=56e6daec4f9fae2da148603883cb2a1f1e2ec086228b7c971486d34a847ac867\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/3a/d3/24bb96c355fdda37c0bee211275b98a3cfc08b33432169ed26\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validators: filename=validators-0.14.1-cp36-none-any.whl size=17239 sha256=5b83734749e031f6ff6aab6a8a0308c8a203328f0dc58f1d0f00faae63d3a899\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/fb/78/272466691f4117974f8d5811e4060fc61e1179a1c00db6f9bb\n",
            "Successfully built pyTigerGraph validators\n",
            "Installing collected packages: validators, pyTigerGraph\n",
            "Successfully installed pyTigerGraph-0.0.4.6 validators-0.14.1\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (6.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Collecting dgl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/3a/34fcdd3ec13cc945db277f87ca8ea3bf320fba8a6c04dc675f257869f45b/dgl-0.4.2-cp36-cp36m-manylinux1_x86_64.whl (2.4MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.17.5)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.6/dist-packages (from dgl) (2.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.4.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.1->dgl) (4.4.1)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-0.4.2\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (2.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx) (4.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHNYpatu4iRl",
        "colab_type": "text"
      },
      "source": [
        "## Importing Packages\n",
        "We now import the packages we just installed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ2QOHOay_ri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pyTigerGraph as tg\n",
        "import dgl\n",
        "import networkx as nx\n",
        "from heapq import nlargest, nsmallest"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nT07WDFn4ocg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##Configuration\n",
        "\n",
        "Here we define some variables, such as the number of epochs of training (usually only need 30 or less for a 2-layer GCN), the learning rate (0.01 seems to work well).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cshhzHac28FQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numEpochs = 25\n",
        "learningRate = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKnPGSqkOio-",
        "colab_type": "text"
      },
      "source": [
        "## Creating the Graph Convolutional Neural Network\n",
        "The block below defines some functions and classes for the GCN. The main ones to look at are the GCNLayer, which are the individual building blocks that the GCN class is made out of. The GCN class defines the structure of our neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alp7UpjBzGWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the message and reduce function\n",
        "# NOTE: We ignore the GCN's normalization constant c_ij for this tutorial.\n",
        "def gcn_message(edges):\n",
        "    # The argument is a batch of edges.\n",
        "    # This computes a (batch of) message called 'msg' using the source node's feature 'h'.\n",
        "    return {'msg' : edges.src['h']}\n",
        "\n",
        "def gcn_reduce(nodes):\n",
        "    # The argument is a batch of nodes.\n",
        "    # This computes the new 'h' features by summing received 'msg' in each node's mailbox.\n",
        "    return {'h' : torch.sum(nodes.mailbox['msg'], dim=1)}\n",
        "\n",
        "# Define the GCNLayer module\n",
        "class GCNLayer(nn.Module):\n",
        "    def __init__(self, in_feats, out_feats):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.linear = nn.Linear(in_feats, out_feats)\n",
        "\n",
        "    def forward(self, g, inputs):\n",
        "        # g is the graph and the inputs is the input node features\n",
        "        # first set the node features\n",
        "        g.ndata['h'] = inputs\n",
        "        # trigger message passing on all edges\n",
        "        g.send(g.edges(), gcn_message)\n",
        "        # trigger aggregation at all nodes\n",
        "        g.recv(g.nodes(), gcn_reduce)\n",
        "        # get the result node features\n",
        "        h = g.ndata.pop('h')\n",
        "        # perform linear transformation\n",
        "        return self.linear(h)\n",
        "\n",
        "# Define a 2-layer GCN model\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_feats, hidden_size, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.gcn1 = GCNLayer(in_feats, hidden_size)\n",
        "        self.gcn2 = GCNLayer(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, g, inputs):\n",
        "        h = self.gcn1(g, inputs)\n",
        "        h = torch.relu(h)\n",
        "        h = self.gcn2(g, h)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs42y-ml41FT",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Creating Database Connection and Creating Edge List\n",
        "\n",
        "This section instantiates a connection to the TigerGraph database and creates a list of tuples which consist of directed edges in the form of (from, to). This is done through two dictionaries that corresponds an article name to a unique numerical id that is needed to process the graph in the GCN.\n",
        "\n",
        "\n",
        "#### **Assumption Alert:** We oversimplify the graph here. The query returns pairs of movies that share the same term (genre). In the real world, most people like a variety of genres and therefore their views are a little more nuanced than creating a graph where the edges are created if the movies share the same genre. Better link creation factors might be actors, directors, etc. but we don't have that in this dataset. Where TigerGraph comes in is the ease of data extraction, as there are no JOIN operations to create these links between movies.\n",
        "* Note: It is possible to create a GCN that has multiple types of verticies, (known as a Relational Graph Convolutional Notebook) but it is more complex. A good way to get started is to simplify until you only have relations between the same type of thing.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27w-wDGIzlxh",
        "colab_type": "code",
        "outputId": "ea40f6b4-12c0-42bd-8894-51332e722359",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "graph = tg.TigerGraphConnection(\n",
        "    ipAddress=\"https://graphml.i.tgcloud.io\", \n",
        "    graphname=\"Recommender\", \n",
        "    apiToken=\"bekr9ls24mlh4kbkd7g28stq8vpj67vi\") # Really not the best idea to have your API key out in the open, but for the sake of the demo, here it is\n",
        "\n",
        "movieToNum = {} # translation dictionary for movie name to number (for dgl)\n",
        "numToMovie = {} # translation dictionary for number to movie name\n",
        "i = 0\n",
        "def createEdgeList(result): # returns tuple of number version of edge\n",
        "    global i\n",
        "    if result[\"src\"] in movieToNum:\n",
        "        fromKey = movieToNum[result[\"src\"]]\n",
        "    else:\n",
        "        movieToNum[result[\"src\"]] = i\n",
        "        numToMovie[i] = result[\"src\"]\n",
        "        fromKey = i\n",
        "        i+=1\n",
        "    if result[\"dest\"] in movieToNum:\n",
        "        toKey = movieToNum[result[\"dest\"]]\n",
        "    else:\n",
        "        movieToNum[result[\"dest\"]] = i\n",
        "        numToMovie[i] = result[\"dest\"]\n",
        "        toKey = i\n",
        "        i+=1\n",
        "    return (fromKey, toKey)\n",
        "    \n",
        "edges = [createEdgeList(thing) for thing in graph.runInstalledQuery(\"movieLinks\", {}, sizeLimit=128000000)[\"results\"][0][\"@@tupleRecords\"]] # creates list of edges\n",
        "print(len(edges))\n",
        "print(edges[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1046378\n",
            "[(0, 1), (2, 1), (3, 1), (4, 1), (5, 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_I2xumq49GH",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Initializing Graph\n",
        "\n",
        "This section converts the list of edges into a graph that DGL can process in the GCN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BNqh7fz0486",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g = nx.Graph()\n",
        "g.add_edges_from(edges)\n",
        "\n",
        "\n",
        "G = dgl.DGLGraph(g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcVoJBlO5B9C",
        "colab_type": "text"
      },
      "source": [
        "## Adding Features to Graph\n",
        "We one-hot encode the features of the verticies in the graph. Feature assignment can be done a multitude of different ways, this is just the fastest and easiest, especially given the lack of attributal information in the dataset.\n",
        "\n",
        "If you had a graph of documents for example, you could run doc2vec on those documents to create a feature vector and create the feature matrix by concatenating those together.\n",
        "\n",
        "Another possiblity is that you have a graph of songs, artists, albums, etc. and you could use tempo, max volume, minimum volume, length, and other numerical descriptions of the song to create the feature matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFom5saG2iwI",
        "colab_type": "code",
        "outputId": "fb0db003-6ac2-468d-9ee1-dcf40249883d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "G.ndata[\"feat\"] = torch.eye(G.number_of_nodes())\n",
        "\n",
        "print(G.nodes[2].data['feat'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 1.,  ..., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svNtInV3FLQx",
        "colab_type": "text"
      },
      "source": [
        "## Get User Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmHzs85ea1aQ",
        "colab_type": "text"
      },
      "source": [
        "In this section, we get a specific user's movie preferences. There is a lot of list comprehension going on, but just know that we are getting the user's 3 highest and lowest reviewed movies for a total of 6 labelled datapoints to feed the GCN. The remainder of the user's data is then processed and saved to test the accuracy of the GCN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy2JYHl6Fj34",
        "colab_type": "code",
        "outputId": "16b3ba0c-8f2c-4bac-e41c-2f450c16b57c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "ratings = graph.runInstalledQuery(\"userRatings\", {\"user\":\"7\"})[\"results\"][0][\"S1\"]\n",
        "print(\"Total Number of Reviews by User: \"+str(len(ratings)))\n",
        "top3Movies = [thing[\"attributes\"][\"movieTitle\"] for thing in nlargest(3, ratings, key=lambda item: item[\"attributes\"][\"userRating\"])] # getting the 3 highest rated movies by the user\n",
        "bottom3Movies = [thing[\"attributes\"][\"movieTitle\"] for thing in nsmallest(3, ratings, key=lambda item: item[\"attributes\"][\"userRating\"])] # getting the 3 lowest rated movies by the user\n",
        "unclassifiedMovies = [thing for thing in ratings if not((thing[\"attributes\"][\"movieTitle\"] in top3Movies) or (thing[\"attributes\"][\"movieTitle\"] in bottom3Movies))]\n",
        "\n",
        "def filterNegative(thing):\n",
        "  if thing[\"attributes\"][\"userRating\"] < 0:\n",
        "    return thing\n",
        "\n",
        "negativeRating = [filterNegative(thing)[\"attributes\"][\"movieTitle\"] for thing in unclassifiedMovies if filterNegative(thing) != None]\n",
        "positiveRating = [thing[\"attributes\"][\"movieTitle\"] for thing in ratings if thing[\"attributes\"][\"movieTitle\"] not in negativeRating]\n",
        "print(\"Number of movies whose rating is unknown to the GCN: \"+str(len(unclassifiedMovies)))\n",
        "print(\"Number of unknown movies with a negative rating: \"+str(len(negativeRating)))\n",
        "print(\"Number of unknown movies with a positive rating: \"+str(len(positiveRating)))\n",
        "print(top3Movies)\n",
        "print(bottom3Movies)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Number of Reviews by User: 403\n",
            "Number of movies whose rating is unknown to the GCN: 397\n",
            "Number of unknown movies with a negative rating: 116\n",
            "Number of unknown movies with a positive rating: 287\n",
            "['Audrey Rose (1977)', 'NeverEnding Story III, The (1994)', 'Boxing Helena (1993)']\n",
            "['Four Weddings and a Funeral (1994)', 'Unbearable Lightness of Being, The (1988)', 'Nightmare on Elm Street, A (1984)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5x-w6Nc5KBT",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Creating Neural Network and Labelling Relevant Verticies\n",
        "\n",
        "Here, we create the GCN. A two-layered GCN appears to work better than deeper networks, and this is further corroborated by the fact [this](https://arxiv.org/abs/1609.02907) paper only used a two-layered one. We also label the wanted and unwanted verticies and setup the optimizer. Since the GCN is a semi-supervised algorithm, we do not label all of the nodes to their correct classes before training - only two are needed!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXBG-rrxFSgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = GCN(G.number_of_nodes(), 20, 2) #Two layer GCN\n",
        "inputs = G.ndata[\"feat\"]\n",
        "labeled_nodes = torch.tensor([movieToNum[top3Movies[0]], movieToNum[top3Movies[1]], movieToNum[top3Movies[2]], \n",
        "                              movieToNum[bottom3Movies[0]], movieToNum[bottom3Movies[1]], movieToNum[bottom3Movies[2]]])  # only the liked movies and the disliked movies are labelled\n",
        "labels = torch.tensor([0, 0, 0, 1, 1, 1])  # their labels are different\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=learningRate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSu33Ee2YKdI",
        "colab_type": "text"
      },
      "source": [
        "## Training Loop\n",
        "Below is the training loop that actually trains the GCN. Unlike many traditional deep learning architectures, GCNs don't always need that much training or as large of data sets due to their exploitation of the *structure* of the data, as opposed to only the features of the data.\n",
        "* Note: due to the randomized initial values of the weights in the neural network, sometimes models don't work very well, or their loss gets stuck at a relatively large number. If that happens, just stop and restart the training process (also rerun the cell above to reset the weights) and hope for better luck!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgkiuuFfOEE-",
        "colab_type": "code",
        "outputId": "e6a461c1-218b-4bbe-af79-660d64955e39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "source": [
        "all_logits = []\n",
        "for epoch in range(numEpochs):\n",
        "    logits = net(G, inputs)\n",
        "    # we save the logits for visualization later\n",
        "    all_logits.append(logits.detach())\n",
        "    logp = F.log_softmax(logits, 1)\n",
        "    # we only compute loss for labeled nodes\n",
        "    loss = F.nll_loss(logp[labeled_nodes], labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch %d | Loss: %6.3e' % (epoch, loss.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 | Loss: 1.356e+01\n",
            "Epoch 1 | Loss: 5.604e+01\n",
            "Epoch 2 | Loss: 1.797e+02\n",
            "Epoch 3 | Loss: 5.909e+01\n",
            "Epoch 4 | Loss: 1.083e+01\n",
            "Epoch 5 | Loss: 8.827e+00\n",
            "Epoch 6 | Loss: 5.314e+00\n",
            "Epoch 7 | Loss: 4.826e-01\n",
            "Epoch 8 | Loss: 5.298e+00\n",
            "Epoch 9 | Loss: 8.436e+00\n",
            "Epoch 10 | Loss: 8.925e+00\n",
            "Epoch 11 | Loss: 7.530e+00\n",
            "Epoch 12 | Loss: 4.470e+00\n",
            "Epoch 13 | Loss: 2.316e-01\n",
            "Epoch 14 | Loss: 4.095e+00\n",
            "Epoch 15 | Loss: 6.054e+00\n",
            "Epoch 16 | Loss: 6.115e+00\n",
            "Epoch 17 | Loss: 4.500e+00\n",
            "Epoch 18 | Loss: 1.413e+00\n",
            "Epoch 19 | Loss: 2.964e+00\n",
            "Epoch 20 | Loss: 5.250e+00\n",
            "Epoch 21 | Loss: 5.706e+00\n",
            "Epoch 22 | Loss: 4.552e+00\n",
            "Epoch 23 | Loss: 1.979e+00\n",
            "Epoch 24 | Loss: 1.850e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxw6_RAdbg82",
        "colab_type": "text"
      },
      "source": [
        "## Testing Accuracy\n",
        "Here is the code that processes the GCN's results and calculates the accuracy based off the verticies that the user has reviewed, but were not labelled in the graph for the GCN to use. While this accuracy is pretty mediocre, the GCN does make predictions based off of movies sharing the same genre, and therefore with better data, there could be (and almost certainly would be) an improvement in accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRbhbVbhOGX1",
        "colab_type": "code",
        "outputId": "91defaa7-ef64-4361-f95a-3b33640fc2ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "predictions = list(all_logits[numEpochs-1])\n",
        "\n",
        "positivePrediction = []\n",
        "negativePrediction = []\n",
        "a = 0\n",
        "for movie in predictions:\n",
        "    if movie[0] >= movie[1]:\n",
        "      positivePrediction.append(numToMovie[a])\n",
        "    else:\n",
        "      negativePrediction.append(numToMovie[a])\n",
        "    a+=1\n",
        "\n",
        "totalPredictions = len(unclassifiedMovies)\n",
        "totalRight = 0\n",
        "\n",
        "for movie in unclassifiedMovies:\n",
        "  if (movie[\"attributes\"][\"movieTitle\"] in negativePrediction) and (movie[\"attributes\"][\"movieTitle\"] in negativeRating):\n",
        "    totalRight += 1\n",
        "  if (movie[\"attributes\"][\"movieTitle\"] in positivePrediction) and (movie[\"attributes\"][\"movieTitle\"] in positiveRating):\n",
        "    totalRight += 1\n",
        "    \n",
        "print(\"Number of movies whose rating is unknown to the GCN: \"+str(len(unclassifiedMovies)))\n",
        "print(\"Total number of correct classifications: \"+str(totalRight))\n",
        "print(\"Accuracy: \"+str(totalRight/totalPredictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of movies whose rating is unknown to the GCN: 397\n",
            "Total number of correct classifications: 164\n",
            "Accuracy: 0.41309823677581864\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnzAPzqXaV34",
        "colab_type": "text"
      },
      "source": [
        "## Credits\n",
        "<p><img alt=\"Picture of Parker Erickson\" height=\"150px\" src=\"https://avatars1.githubusercontent.com/u/9616171?s=460&v=4\" align=\"right\" hspace=\"20px\" vspace=\"20px\"></p>\n",
        "\n",
        "Demo/tutorial written by Parker Erickson, a student at the University of Minnesota pursuing a B.S. in Computer Science. His interests include graph databases, machine learning, travelling, playing the saxophone, and watching Minnesota Twins baseball. Feel free to reach out! Find him on:\n",
        "\n",
        "* LinkedIn: [https://www.linkedin.com/in/parker-erickson/](https://www.linkedin.com/in/parker-erickson/)\n",
        "* GitHub: [https://github.com/parkererickson](https://github.com/parkererickson)\n",
        "* Medium: [https://medium.com/@parker.erickson](https://medium.com/@parker.erickson)\n",
        "* Email: parker.erickson30@gmail.com\n",
        "----\n",
        "GCN Resources:\n",
        "* DGL Documentation: [https://docs.dgl.ai/](https://docs.dgl.ai/)\n",
        "* GCN paper by Kipf and Welling [https://arxiv.org/abs/1609.02907](https://arxiv.org/abs/1609.02907)\n",
        "* R-GCN paper: [https://arxiv.org/abs/1703.06103](https://arxiv.org/abs/1703.06103)\n",
        "---- \n",
        "Notebook adapted from: [https://docs.dgl.ai/en/latest/tutorials/basics/1_first.html](https://docs.dgl.ai/en/latest/tutorials/basics/1_first.html)"
      ]
    }
  ]
}